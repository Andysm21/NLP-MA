{"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8448914,"sourceType":"datasetVersion","datasetId":5034754},{"sourceId":8449664,"sourceType":"datasetVersion","datasetId":5035332}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2024-05-18T11:55:27.323097Z","iopub.execute_input":"2024-05-18T11:55:27.324167Z","iopub.status.idle":"2024-05-18T11:55:28.253694Z","shell.execute_reply.started":"2024-05-18T11:55:27.324130Z","shell.execute_reply":"2024-05-18T11:55:28.252787Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# Importing dataset\n","metadata":{"id":"daBLi64FV88C"}},{"cell_type":"code","source":"# !kaggle datasets download -d notshrirang/spotify-million-song-dataset","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"puR2ovAMWDUe","outputId":"5bb411c7-0be3-45c7-8a3d-2cf8a896d80f","execution":{"iopub.status.busy":"2024-05-18T11:55:28.255883Z","iopub.execute_input":"2024-05-18T11:55:28.256446Z","iopub.status.idle":"2024-05-18T11:55:28.261152Z","shell.execute_reply.started":"2024-05-18T11:55:28.256409Z","shell.execute_reply":"2024-05-18T11:55:28.260083Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# %unzip spotify-million-song-dataset.zip","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mOpLbsT_XkkV","outputId":"d47c9ae8-f12f-4679-d646-cf40aa45f441","execution":{"iopub.status.busy":"2024-05-18T11:55:28.262443Z","iopub.execute_input":"2024-05-18T11:55:28.262707Z","iopub.status.idle":"2024-05-18T11:55:28.274025Z","shell.execute_reply.started":"2024-05-18T11:55:28.262684Z","shell.execute_reply":"2024-05-18T11:55:28.273000Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"spotifyDF = pd.read_csv(\"/kaggle/input/spotifyfull/spotify_millsongdata.csv\")","metadata":{"id":"fF9qzQIHYupy","execution":{"iopub.status.busy":"2024-05-18T11:55:28.276997Z","iopub.execute_input":"2024-05-18T11:55:28.277417Z","iopub.status.idle":"2024-05-18T11:55:30.197930Z","shell.execute_reply.started":"2024-05-18T11:55:28.277383Z","shell.execute_reply":"2024-05-18T11:55:30.196681Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# Milestone 3","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer, TFT5ForConditionalGeneration\n\ntokenizer = AutoTokenizer.from_pretrained(\"google-t5/t5-small\")\nmodel = TFT5ForConditionalGeneration.from_pretrained(\"google-t5/t5-small\")","metadata":{"execution":{"iopub.status.busy":"2024-05-18T11:55:30.199266Z","iopub.execute_input":"2024-05-18T11:55:30.199607Z","iopub.status.idle":"2024-05-18T11:55:51.740333Z","shell.execute_reply.started":"2024-05-18T11:55:30.199578Z","shell.execute_reply":"2024-05-18T11:55:51.739574Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"2024-05-18 11:55:37.754878: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-05-18 11:55:37.754998: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-05-18 11:55:37.877155: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/2.32k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"01aa1943596942ccbeede0c66488fbb3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"165b3621c4ed41fa8abdcbde136ae33f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c608cdf7f2d1498a84bf398e5b7e771f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"37524b1281f34dd0a330403483d4eefd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d7f1674f77764572bfb6a6978a680fad"}},"metadata":{}},{"name":"stderr","text":"All PyTorch model weights were used when initializing TFT5ForConditionalGeneration.\n\nAll the weights of TFT5ForConditionalGeneration were initialized from the PyTorch model.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n","output_type":"stream"}]},{"cell_type":"code","source":"spotifyDFMS3=spotifyDF.copy()","metadata":{"execution":{"iopub.status.busy":"2024-05-18T11:55:51.741440Z","iopub.execute_input":"2024-05-18T11:55:51.741713Z","iopub.status.idle":"2024-05-18T11:55:51.749080Z","shell.execute_reply.started":"2024-05-18T11:55:51.741689Z","shell.execute_reply":"2024-05-18T11:55:51.748155Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def split_sentences(df, col_name):\n    df['X'] = df[col_name].apply(lambda x: ' '.join(x.split()[:len(x.split())//2]))\n    df['Y'] = df[col_name].apply(lambda x: ' '.join(x.split()[len(x.split())//2:]))\n    return df\n\nspotifyDFMS3=split_sentences(spotifyDFMS3,\"text\")\nspotifyDFMS3.head(2)","metadata":{"execution":{"iopub.status.busy":"2024-05-18T11:55:51.750185Z","iopub.execute_input":"2024-05-18T11:55:51.750476Z","iopub.status.idle":"2024-05-18T11:55:55.891728Z","shell.execute_reply.started":"2024-05-18T11:55:51.750443Z","shell.execute_reply":"2024-05-18T11:55:55.890728Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"  artist                   song                                        link  \\\n0   ABBA  Ahe's My Kind Of Girl  /a/abba/ahes+my+kind+of+girl_20598417.html   \n1   ABBA       Andante, Andante       /a/abba/andante+andante_20002708.html   \n\n                                                text  \\\n0  Look at her face, it's a wonderful face  \\r\\nA...   \n1  Take it easy with me, please  \\r\\nTouch me gen...   \n\n                                                   X  \\\n0  Look at her face, it's a wonderful face And it...   \n1  Take it easy with me, please Touch me gently l...   \n\n                                                   Y  \n0  And when we go for a walk in the park And she ...  \n1  your eyes Like the feeling of a thousand butte...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>artist</th>\n      <th>song</th>\n      <th>link</th>\n      <th>text</th>\n      <th>X</th>\n      <th>Y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ABBA</td>\n      <td>Ahe's My Kind Of Girl</td>\n      <td>/a/abba/ahes+my+kind+of+girl_20598417.html</td>\n      <td>Look at her face, it's a wonderful face  \\r\\nA...</td>\n      <td>Look at her face, it's a wonderful face And it...</td>\n      <td>And when we go for a walk in the park And she ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ABBA</td>\n      <td>Andante, Andante</td>\n      <td>/a/abba/andante+andante_20002708.html</td>\n      <td>Take it easy with me, please  \\r\\nTouch me gen...</td>\n      <td>Take it easy with me, please Touch me gently l...</td>\n      <td>your eyes Like the feeling of a thousand butte...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"print(len(spotifyDFMS3[\"Y\"][0])+len(spotifyDFMS3[\"X\"][0]))\nprint(len(spotifyDFMS3[\"text\"][0]))","metadata":{"execution":{"iopub.status.busy":"2024-05-18T11:55:55.893033Z","iopub.execute_input":"2024-05-18T11:55:55.893372Z","iopub.status.idle":"2024-05-18T11:55:55.899216Z","shell.execute_reply.started":"2024-05-18T11:55:55.893345Z","shell.execute_reply":"2024-05-18T11:55:55.898198Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"719\n781\n","output_type":"stream"}]},{"cell_type":"markdown","source":"There is a difference in the values since the split_sentences method also removes the extra unneeded tokens such as white spaces adn \\n.","metadata":{}},{"cell_type":"code","source":"spotifyDFMS3['artist_lyric']=spotifyDFMS3[\"artist\"]+\" || \"+spotifyDFMS3[\"X\"]","metadata":{"execution":{"iopub.status.busy":"2024-05-18T11:55:55.900613Z","iopub.execute_input":"2024-05-18T11:55:55.901272Z","iopub.status.idle":"2024-05-18T11:55:55.956573Z","shell.execute_reply.started":"2024-05-18T11:55:55.901228Z","shell.execute_reply":"2024-05-18T11:55:55.955583Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"spotifyDFMS3.head(2)","metadata":{"execution":{"iopub.status.busy":"2024-05-18T11:55:55.961308Z","iopub.execute_input":"2024-05-18T11:55:55.961639Z","iopub.status.idle":"2024-05-18T11:55:55.975279Z","shell.execute_reply.started":"2024-05-18T11:55:55.961611Z","shell.execute_reply":"2024-05-18T11:55:55.974225Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"  artist                   song                                        link  \\\n0   ABBA  Ahe's My Kind Of Girl  /a/abba/ahes+my+kind+of+girl_20598417.html   \n1   ABBA       Andante, Andante       /a/abba/andante+andante_20002708.html   \n\n                                                text  \\\n0  Look at her face, it's a wonderful face  \\r\\nA...   \n1  Take it easy with me, please  \\r\\nTouch me gen...   \n\n                                                   X  \\\n0  Look at her face, it's a wonderful face And it...   \n1  Take it easy with me, please Touch me gently l...   \n\n                                                   Y  \\\n0  And when we go for a walk in the park And she ...   \n1  your eyes Like the feeling of a thousand butte...   \n\n                                        artist_lyric  \n0  ABBA || Look at her face, it's a wonderful fac...  \n1  ABBA || Take it easy with me, please Touch me ...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>artist</th>\n      <th>song</th>\n      <th>link</th>\n      <th>text</th>\n      <th>X</th>\n      <th>Y</th>\n      <th>artist_lyric</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ABBA</td>\n      <td>Ahe's My Kind Of Girl</td>\n      <td>/a/abba/ahes+my+kind+of+girl_20598417.html</td>\n      <td>Look at her face, it's a wonderful face  \\r\\nA...</td>\n      <td>Look at her face, it's a wonderful face And it...</td>\n      <td>And when we go for a walk in the park And she ...</td>\n      <td>ABBA || Look at her face, it's a wonderful fac...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ABBA</td>\n      <td>Andante, Andante</td>\n      <td>/a/abba/andante+andante_20002708.html</td>\n      <td>Take it easy with me, please  \\r\\nTouch me gen...</td>\n      <td>Take it easy with me, please Touch me gently l...</td>\n      <td>your eyes Like the feeling of a thousand butte...</td>\n      <td>ABBA || Take it easy with me, please Touch me ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"def max_words(df, col_name):\n    max_word_count = df[col_name].apply(lambda x: len(x.split(\" \"))).max()\n    return max_word_count\n\nmax_word_count_X = max_words(spotifyDFMS3, 'X')\nmax_word_count_Y = max_words(spotifyDFMS3, 'Y')\nmax_word_count = max_words(spotifyDFMS3, 'artist_lyric')\nprint(\"X max :\", max_word_count_X)\nprint(\"Y max :\", max_word_count_Y)\nprint(\"X AND artist max:\",max_word_count)","metadata":{"execution":{"iopub.status.busy":"2024-05-18T11:55:55.976512Z","iopub.execute_input":"2024-05-18T11:55:55.976818Z","iopub.status.idle":"2024-05-18T11:55:57.359322Z","shell.execute_reply.started":"2024-05-18T11:55:55.976793Z","shell.execute_reply":"2024-05-18T11:55:57.358179Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"X max : 413\nY max : 414\nX AND artist max: 416\n","output_type":"stream"}]},{"cell_type":"code","source":"from datasets import load_dataset\nspotifyDataset = load_dataset('csv',data_files=\"/kaggle/input/spotifyfull/spotify_millsongdata.csv\", split=\"train\")","metadata":{"execution":{"iopub.status.busy":"2024-05-18T11:55:57.360864Z","iopub.execute_input":"2024-05-18T11:55:57.361202Z","iopub.status.idle":"2024-05-18T11:55:59.048275Z","shell.execute_reply.started":"2024-05-18T11:55:57.361176Z","shell.execute_reply":"2024-05-18T11:55:59.047443Z"},"trusted":true},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"013f00c2ab064a93b2a7859e74430912"}},"metadata":{}}]},{"cell_type":"code","source":"type(spotifyDataset)","metadata":{"execution":{"iopub.status.busy":"2024-05-18T11:55:59.049569Z","iopub.execute_input":"2024-05-18T11:55:59.050343Z","iopub.status.idle":"2024-05-18T11:55:59.056686Z","shell.execute_reply.started":"2024-05-18T11:55:59.050306Z","shell.execute_reply":"2024-05-18T11:55:59.055607Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"datasets.arrow_dataset.Dataset"},"metadata":{}}]},{"cell_type":"code","source":"def split_sentences(df,OldDF):\n    x=[]\n    y=[]\n    artist_lyric=[]\n    for string in OldDF[\"X\"]:\n        x.append(string)\n    for string in OldDF[\"Y\"]:\n        y.append(string)\n    for string in OldDF[\"artist_lyric\"]:\n        artist_lyric.append(string)\n    df = df.add_column(\"X\", x)\n    df = df.add_column(\"Y\", y)\n    df = df.add_column(\"artist_lyric\", artist_lyric)\n    return df\n\nspotifyDataset=split_sentences(spotifyDataset,spotifyDFMS3)","metadata":{"execution":{"iopub.status.busy":"2024-05-18T11:55:59.058052Z","iopub.execute_input":"2024-05-18T11:55:59.058396Z","iopub.status.idle":"2024-05-18T11:56:00.470642Z","shell.execute_reply.started":"2024-05-18T11:55:59.058369Z","shell.execute_reply":"2024-05-18T11:56:00.469674Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"spotifyDataset[0]","metadata":{"execution":{"iopub.status.busy":"2024-05-18T11:56:00.471985Z","iopub.execute_input":"2024-05-18T11:56:00.472298Z","iopub.status.idle":"2024-05-18T11:56:00.482164Z","shell.execute_reply.started":"2024-05-18T11:56:00.472259Z","shell.execute_reply":"2024-05-18T11:56:00.481119Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"{'artist': 'ABBA',\n 'song': \"Ahe's My Kind Of Girl\",\n 'link': '/a/abba/ahes+my+kind+of+girl_20598417.html',\n 'text': \"Look at her face, it's a wonderful face  \\r\\nAnd it means something special to me  \\r\\nLook at the way that she smiles when she sees me  \\r\\nHow lucky can one fellow be?  \\r\\n  \\r\\nShe's just my kind of girl, she makes me feel fine  \\r\\nWho could ever believe that she could be mine?  \\r\\nShe's just my kind of girl, without her I'm blue  \\r\\nAnd if she ever leaves me what could I do, what could I do?  \\r\\n  \\r\\nAnd when we go for a walk in the park  \\r\\nAnd she holds me and squeezes my hand  \\r\\nWe'll go on walking for hours and talking  \\r\\nAbout all the things that we plan  \\r\\n  \\r\\nShe's just my kind of girl, she makes me feel fine  \\r\\nWho could ever believe that she could be mine?  \\r\\nShe's just my kind of girl, without her I'm blue  \\r\\nAnd if she ever leaves me what could I do, what could I do?\\r\\n\\r\\n\",\n 'X': \"Look at her face, it's a wonderful face And it means something special to me Look at the way that she smiles when she sees me How lucky can one fellow be? She's just my kind of girl, she makes me feel fine Who could ever believe that she could be mine? She's just my kind of girl, without her I'm blue And if she ever leaves me what could I do, what could I do?\",\n 'Y': \"And when we go for a walk in the park And she holds me and squeezes my hand We'll go on walking for hours and talking About all the things that we plan She's just my kind of girl, she makes me feel fine Who could ever believe that she could be mine? She's just my kind of girl, without her I'm blue And if she ever leaves me what could I do, what could I do?\",\n 'artist_lyric': \"ABBA || Look at her face, it's a wonderful face And it means something special to me Look at the way that she smiles when she sees me How lucky can one fellow be? She's just my kind of girl, she makes me feel fine Who could ever believe that she could be mine? She's just my kind of girl, without her I'm blue And if she ever leaves me what could I do, what could I do?\"}"},"metadata":{}}]},{"cell_type":"code","source":"columns_to_drop = [\"song\", \"link\",\"text\"]\nspotifyDataset = spotifyDataset.remove_columns(columns_to_drop)","metadata":{"execution":{"iopub.status.busy":"2024-05-18T11:56:00.483579Z","iopub.execute_input":"2024-05-18T11:56:00.483985Z","iopub.status.idle":"2024-05-18T11:56:00.498610Z","shell.execute_reply.started":"2024-05-18T11:56:00.483952Z","shell.execute_reply":"2024-05-18T11:56:00.497750Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"spotifyDataset[0]","metadata":{"execution":{"iopub.status.busy":"2024-05-18T11:56:00.499980Z","iopub.execute_input":"2024-05-18T11:56:00.500336Z","iopub.status.idle":"2024-05-18T11:56:00.511210Z","shell.execute_reply.started":"2024-05-18T11:56:00.500305Z","shell.execute_reply":"2024-05-18T11:56:00.510207Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"{'artist': 'ABBA',\n 'X': \"Look at her face, it's a wonderful face And it means something special to me Look at the way that she smiles when she sees me How lucky can one fellow be? She's just my kind of girl, she makes me feel fine Who could ever believe that she could be mine? She's just my kind of girl, without her I'm blue And if she ever leaves me what could I do, what could I do?\",\n 'Y': \"And when we go for a walk in the park And she holds me and squeezes my hand We'll go on walking for hours and talking About all the things that we plan She's just my kind of girl, she makes me feel fine Who could ever believe that she could be mine? She's just my kind of girl, without her I'm blue And if she ever leaves me what could I do, what could I do?\",\n 'artist_lyric': \"ABBA || Look at her face, it's a wonderful face And it means something special to me Look at the way that she smiles when she sees me How lucky can one fellow be? She's just my kind of girl, she makes me feel fine Who could ever believe that she could be mine? She's just my kind of girl, without her I'm blue And if she ever leaves me what could I do, what could I do?\"}"},"metadata":{}}]},{"cell_type":"code","source":"spotifyDataset","metadata":{"execution":{"iopub.status.busy":"2024-05-18T11:56:00.512423Z","iopub.execute_input":"2024-05-18T11:56:00.513033Z","iopub.status.idle":"2024-05-18T11:56:00.522870Z","shell.execute_reply.started":"2024-05-18T11:56:00.512995Z","shell.execute_reply":"2024-05-18T11:56:00.521571Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['artist', 'X', 'Y', 'artist_lyric'],\n    num_rows: 57650\n})"},"metadata":{}}]},{"cell_type":"code","source":"def process_dataset(example):\n    artist = example['artist']\n    first_half = example['X']\n    second_half = example['Y']\n    \n    input_text = f\"{artist}: {first_half}\"\n    target_text = second_half\n    \n    return {'input_text': input_text, 'target_text': target_text}\n\nspotifyDataset = spotifyDataset.map(process_dataset, remove_columns=[\"X\", \"Y\", \"artist_lyric\"])","metadata":{"execution":{"iopub.status.busy":"2024-05-18T11:56:00.524374Z","iopub.execute_input":"2024-05-18T11:56:00.524817Z","iopub.status.idle":"2024-05-18T11:56:06.462147Z","shell.execute_reply.started":"2024-05-18T11:56:00.524768Z","shell.execute_reply":"2024-05-18T11:56:06.461172Z"},"trusted":true},"execution_count":19,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/57650 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d8bee6ac423c4c7688dfba446f1f3e4f"}},"metadata":{}}]},{"cell_type":"code","source":"spotifyDataset","metadata":{"execution":{"iopub.status.busy":"2024-05-18T11:56:06.463454Z","iopub.execute_input":"2024-05-18T11:56:06.463790Z","iopub.status.idle":"2024-05-18T11:56:06.470773Z","shell.execute_reply.started":"2024-05-18T11:56:06.463762Z","shell.execute_reply":"2024-05-18T11:56:06.469600Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['artist', 'input_text', 'target_text'],\n    num_rows: 57650\n})"},"metadata":{}}]},{"cell_type":"code","source":"def tokenize_function(examples):\n    inputs = [f\"<s> {text} </s>\" for text in examples['input_text']]\n    targets = [f\"<s> {text} </s>\" for text in examples['target_text']]\n    model_inputs = tokenizer(inputs, max_length=max_word_count, truncation=True, padding=\"max_length\")\n    labels = tokenizer(targets, max_length=max_word_count, truncation=True, padding=\"max_length\")\n    \n    model_inputs[\"labels\"] = labels[\"input_ids\"]\n    decoder_input_ids = labels['input_ids'].copy()\n    decoder_start_token_id = tokenizer.pad_token_id\n    \n    for idx in range(len(decoder_input_ids)):\n        decoder_input_ids[idx] = [decoder_start_token_id] + decoder_input_ids[idx][:-1]\n    \n    model_inputs[\"labels\"] = labels[\"input_ids\"]\n    model_inputs[\"decoder_input_ids\"] = decoder_input_ids\n\n    return model_inputs\n\nspotifyDataset = spotifyDataset.map(tokenize_function, batched=True, remove_columns=[\"artist\", \"input_text\", \"target_text\"])","metadata":{"execution":{"iopub.status.busy":"2024-05-18T11:56:06.472187Z","iopub.execute_input":"2024-05-18T11:56:06.472574Z","iopub.status.idle":"2024-05-18T11:56:59.592141Z","shell.execute_reply.started":"2024-05-18T11:56:06.472540Z","shell.execute_reply":"2024-05-18T11:56:59.590989Z"},"trusted":true},"execution_count":21,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/57650 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c574957dcaae45978d73a2ced5f23d75"}},"metadata":{}}]},{"cell_type":"code","source":"spotifyDataset","metadata":{"execution":{"iopub.status.busy":"2024-05-18T11:56:59.593406Z","iopub.execute_input":"2024-05-18T11:56:59.593732Z","iopub.status.idle":"2024-05-18T11:56:59.600656Z","shell.execute_reply.started":"2024-05-18T11:56:59.593705Z","shell.execute_reply":"2024-05-18T11:56:59.599511Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['input_ids', 'attention_mask', 'labels', 'decoder_input_ids'],\n    num_rows: 57650\n})"},"metadata":{}}]},{"cell_type":"code","source":"type(spotifyDataset)","metadata":{"execution":{"iopub.status.busy":"2024-05-18T11:56:59.602004Z","iopub.execute_input":"2024-05-18T11:56:59.602329Z","iopub.status.idle":"2024-05-18T11:57:00.287954Z","shell.execute_reply.started":"2024-05-18T11:56:59.602276Z","shell.execute_reply":"2024-05-18T11:57:00.286907Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"datasets.arrow_dataset.Dataset"},"metadata":{}}]},{"cell_type":"code","source":"spotifyDataset=spotifyDataset.train_test_split(test_size=0.2)","metadata":{"execution":{"iopub.status.busy":"2024-05-18T11:57:00.289304Z","iopub.execute_input":"2024-05-18T11:57:00.290146Z","iopub.status.idle":"2024-05-18T11:57:00.334769Z","shell.execute_reply.started":"2024-05-18T11:57:00.290100Z","shell.execute_reply":"2024-05-18T11:57:00.333650Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"spotifyDataset","metadata":{"execution":{"iopub.status.busy":"2024-05-18T11:57:00.336115Z","iopub.execute_input":"2024-05-18T11:57:00.336453Z","iopub.status.idle":"2024-05-18T11:57:00.343177Z","shell.execute_reply.started":"2024-05-18T11:57:00.336425Z","shell.execute_reply":"2024-05-18T11:57:00.342313Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['input_ids', 'attention_mask', 'labels', 'decoder_input_ids'],\n        num_rows: 46120\n    })\n    test: Dataset({\n        features: ['input_ids', 'attention_mask', 'labels', 'decoder_input_ids'],\n        num_rows: 11530\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"train_dataset = spotifyDataset[\"train\"].with_format(\"numpy\")[:] \ntest_dataset = spotifyDataset[\"test\"].with_format(\"numpy\")[:]","metadata":{"execution":{"iopub.status.busy":"2024-05-18T11:57:00.344551Z","iopub.execute_input":"2024-05-18T11:57:00.344869Z","iopub.status.idle":"2024-05-18T11:57:04.562651Z","shell.execute_reply.started":"2024-05-18T11:57:00.344843Z","shell.execute_reply":"2024-05-18T11:57:04.561596Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\n\noptimizer = keras.optimizers.Adam(learning_rate=5e-5)\nloss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\nmetrics = [tf.keras.metrics.SparseCategoricalAccuracy()]","metadata":{"execution":{"iopub.status.busy":"2024-05-18T11:57:04.565304Z","iopub.execute_input":"2024-05-18T11:57:04.565651Z","iopub.status.idle":"2024-05-18T11:57:04.688957Z","shell.execute_reply.started":"2024-05-18T11:57:04.565623Z","shell.execute_reply":"2024-05-18T11:57:04.687880Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"# model.compile(optimizer=optimizer, loss=loss, metrics=metrics)","metadata":{"execution":{"iopub.status.busy":"2024-05-18T11:57:04.694120Z","iopub.execute_input":"2024-05-18T11:57:04.694481Z","iopub.status.idle":"2024-05-18T11:57:04.698841Z","shell.execute_reply.started":"2024-05-18T11:57:04.694453Z","shell.execute_reply":"2024-05-18T11:57:04.697834Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"# model.fit(train_dataset, validation_data=test_dataset, epochs=1)","metadata":{"execution":{"iopub.status.busy":"2024-05-18T11:57:04.700217Z","iopub.execute_input":"2024-05-18T11:57:04.700560Z","iopub.status.idle":"2024-05-18T11:57:04.712514Z","shell.execute_reply.started":"2024-05-18T11:57:04.700534Z","shell.execute_reply":"2024-05-18T11:57:04.711451Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\n\noptimizer = keras.optimizers.Adam(learning_rate=5e-5)\nloss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\naccuracy_metric = tf.keras.metrics.SparseCategoricalAccuracy(name='accuracy')","metadata":{"execution":{"iopub.status.busy":"2024-05-18T11:57:04.713806Z","iopub.execute_input":"2024-05-18T11:57:04.714145Z","iopub.status.idle":"2024-05-18T11:57:04.731775Z","shell.execute_reply.started":"2024-05-18T11:57:04.714118Z","shell.execute_reply":"2024-05-18T11:57:04.730638Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"def convert_to_tf_dataset(hf_dataset):\n    return hf_dataset.to_tf_dataset(\n        columns=['input_ids', 'attention_mask', 'decoder_input_ids', 'labels'],\n        shuffle=True,\n        batch_size=1\n    )\n\ntrain_dataset = convert_to_tf_dataset(spotifyDataset['train'])\neval_dataset = convert_to_tf_dataset(spotifyDataset['test'])","metadata":{"execution":{"iopub.status.busy":"2024-05-18T11:57:04.733258Z","iopub.execute_input":"2024-05-18T11:57:04.733598Z","iopub.status.idle":"2024-05-18T11:57:05.292196Z","shell.execute_reply.started":"2024-05-18T11:57:04.733572Z","shell.execute_reply":"2024-05-18T11:57:05.291067Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"def train_step(batch):\n    with tf.GradientTape() as tape:\n        outputs = model(input_ids=batch['input_ids'], attention_mask=batch['attention_mask'], decoder_input_ids=batch['decoder_input_ids'], labels=batch['labels'])\n        loss = outputs.loss\n        logits = outputs.logits\n    gradients = tape.gradient(loss, model.trainable_variables)\n    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n    accuracy_metric.update_state(batch['labels'], logits)\n    return loss","metadata":{"execution":{"iopub.status.busy":"2024-05-18T11:57:05.293601Z","iopub.execute_input":"2024-05-18T11:57:05.293935Z","iopub.status.idle":"2024-05-18T11:57:05.300952Z","shell.execute_reply.started":"2024-05-18T11:57:05.293909Z","shell.execute_reply":"2024-05-18T11:57:05.299816Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"def eval_step(batch):\n    outputs = model(input_ids=batch['input_ids'], attention_mask=batch['attention_mask'], decoder_input_ids=batch['decoder_input_ids'], labels=batch['labels'])\n    loss = outputs.loss\n    logits = outputs.logits\n    accuracy_metric.update_state(batch['labels'], logits)\n    return loss","metadata":{"execution":{"iopub.status.busy":"2024-05-18T11:57:05.302205Z","iopub.execute_input":"2024-05-18T11:57:05.302860Z","iopub.status.idle":"2024-05-18T11:57:05.313252Z","shell.execute_reply.started":"2024-05-18T11:57:05.302829Z","shell.execute_reply":"2024-05-18T11:57:05.312164Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"num_epochs = 5\ntrain_steps = len(train_dataset)\neval_steps = len(eval_dataset)","metadata":{"execution":{"iopub.status.busy":"2024-05-18T11:57:05.314556Z","iopub.execute_input":"2024-05-18T11:57:05.314878Z","iopub.status.idle":"2024-05-18T11:57:05.327843Z","shell.execute_reply.started":"2024-05-18T11:57:05.314847Z","shell.execute_reply":"2024-05-18T11:57:05.326697Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"for epoch in range(num_epochs):\n    # Training\n    print('TRAINING')\n    print(f\"Epoch {epoch+1}/{num_epochs}\")\n    total_loss = 0.0\n    accuracy_metric.reset_states()\n    for step, batch in enumerate(train_dataset):\n        loss = train_step(batch)\n        total_loss += tf.reduce_mean(loss).numpy()\n        if (step + 1) % 100 == 0:\n            print(f\"Step {step+1}/{train_steps}, Loss: {total_loss / (step+1):.4f}, Accuracy: {accuracy_metric.result().numpy():.4f}\")\n    \n    # Evaluation\n    print('EVALUATION')\n    total_loss = 0.0\n    accuracy_metric.reset_states()\n    for step, batch in enumerate(eval_dataset):\n        loss = eval_step(batch)\n        total_loss += tf.reduce_mean(loss).numpy()\n    #2:57\n    print(f\"Validation Loss: {total_loss / eval_steps:.4f}, Validation Accuracy: {accuracy_metric.result().numpy():.4f}\")","metadata":{"execution":{"iopub.status.busy":"2024-05-18T11:58:32.967800Z","iopub.execute_input":"2024-05-18T11:58:32.968590Z","iopub.status.idle":"2024-05-18T14:17:02.187097Z","shell.execute_reply.started":"2024-05-18T11:58:32.968557Z","shell.execute_reply":"2024-05-18T14:17:02.184310Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"TRAINING\nEpoch 1/5\nStep 100/46120, Loss: 1.2683, Accuracy: 0.7944\nStep 200/46120, Loss: 1.1351, Accuracy: 0.8125\nStep 300/46120, Loss: 1.1189, Accuracy: 0.8135\nStep 400/46120, Loss: 1.1247, Accuracy: 0.8108\nStep 500/46120, Loss: 1.1105, Accuracy: 0.8125\nStep 600/46120, Loss: 1.1322, Accuracy: 0.8089\nStep 700/46120, Loss: 1.0966, Accuracy: 0.8139\nStep 800/46120, Loss: 1.0763, Accuracy: 0.8166\nStep 900/46120, Loss: 1.0721, Accuracy: 0.8171\nStep 1000/46120, Loss: 1.0749, Accuracy: 0.8162\nStep 1100/46120, Loss: 1.0722, Accuracy: 0.8165\nStep 1200/46120, Loss: 1.0723, Accuracy: 0.8162\nStep 1300/46120, Loss: 1.0617, Accuracy: 0.8179\nStep 1400/46120, Loss: 1.0521, Accuracy: 0.8193\nStep 1500/46120, Loss: 1.0604, Accuracy: 0.8179\nStep 1600/46120, Loss: 1.0577, Accuracy: 0.8182\nStep 1700/46120, Loss: 1.0519, Accuracy: 0.8191\nStep 1800/46120, Loss: 1.0432, Accuracy: 0.8203\nStep 1900/46120, Loss: 1.0444, Accuracy: 0.8200\nStep 2000/46120, Loss: 1.0427, Accuracy: 0.8201\nStep 2100/46120, Loss: 1.0401, Accuracy: 0.8205\nStep 2200/46120, Loss: 1.0383, Accuracy: 0.8207\nStep 2300/46120, Loss: 1.0370, Accuracy: 0.8208\nStep 2400/46120, Loss: 1.0315, Accuracy: 0.8216\nStep 2500/46120, Loss: 1.0277, Accuracy: 0.8221\nStep 2600/46120, Loss: 1.0252, Accuracy: 0.8225\nStep 2700/46120, Loss: 1.0248, Accuracy: 0.8225\nStep 2800/46120, Loss: 1.0240, Accuracy: 0.8226\nStep 2900/46120, Loss: 1.0249, Accuracy: 0.8224\nStep 3000/46120, Loss: 1.0252, Accuracy: 0.8223\nStep 3100/46120, Loss: 1.0233, Accuracy: 0.8226\nStep 3200/46120, Loss: 1.0237, Accuracy: 0.8224\nStep 3300/46120, Loss: 1.0193, Accuracy: 0.8230\nStep 3400/46120, Loss: 1.0169, Accuracy: 0.8234\nStep 3500/46120, Loss: 1.0140, Accuracy: 0.8238\nStep 3600/46120, Loss: 1.0143, Accuracy: 0.8237\nStep 3700/46120, Loss: 1.0127, Accuracy: 0.8238\nStep 3800/46120, Loss: 1.0097, Accuracy: 0.8243\nStep 3900/46120, Loss: 1.0084, Accuracy: 0.8244\nStep 4000/46120, Loss: 1.0083, Accuracy: 0.8245\nStep 4100/46120, Loss: 1.0067, Accuracy: 0.8247\nStep 4200/46120, Loss: 1.0051, Accuracy: 0.8250\nStep 4300/46120, Loss: 1.0031, Accuracy: 0.8253\nStep 4400/46120, Loss: 1.0013, Accuracy: 0.8256\nStep 4500/46120, Loss: 0.9979, Accuracy: 0.8262\nStep 4600/46120, Loss: 0.9949, Accuracy: 0.8266\nStep 4700/46120, Loss: 0.9922, Accuracy: 0.8270\nStep 4800/46120, Loss: 0.9919, Accuracy: 0.8270\nStep 4900/46120, Loss: 0.9915, Accuracy: 0.8271\nStep 5000/46120, Loss: 0.9934, Accuracy: 0.8267\nStep 5100/46120, Loss: 0.9918, Accuracy: 0.8269\nStep 5200/46120, Loss: 0.9897, Accuracy: 0.8272\nStep 5300/46120, Loss: 0.9861, Accuracy: 0.8277\nStep 5400/46120, Loss: 0.9850, Accuracy: 0.8279\nStep 5500/46120, Loss: 0.9829, Accuracy: 0.8281\nStep 5600/46120, Loss: 0.9841, Accuracy: 0.8278\nStep 5700/46120, Loss: 0.9825, Accuracy: 0.8281\nStep 5800/46120, Loss: 0.9814, Accuracy: 0.8282\nStep 5900/46120, Loss: 0.9804, Accuracy: 0.8283\nStep 6000/46120, Loss: 0.9808, Accuracy: 0.8283\nStep 6100/46120, Loss: 0.9807, Accuracy: 0.8282\nStep 6200/46120, Loss: 0.9804, Accuracy: 0.8281\nStep 6300/46120, Loss: 0.9800, Accuracy: 0.8281\nStep 6400/46120, Loss: 0.9782, Accuracy: 0.8284\nStep 6500/46120, Loss: 0.9767, Accuracy: 0.8286\nStep 6600/46120, Loss: 0.9750, Accuracy: 0.8289\nStep 6700/46120, Loss: 0.9734, Accuracy: 0.8291\nStep 6800/46120, Loss: 0.9727, Accuracy: 0.8292\nStep 6900/46120, Loss: 0.9728, Accuracy: 0.8291\nStep 7000/46120, Loss: 0.9727, Accuracy: 0.8291\nStep 7100/46120, Loss: 0.9723, Accuracy: 0.8292\nStep 7200/46120, Loss: 0.9717, Accuracy: 0.8293\nStep 7300/46120, Loss: 0.9707, Accuracy: 0.8294\nStep 7400/46120, Loss: 0.9690, Accuracy: 0.8297\nStep 7500/46120, Loss: 0.9681, Accuracy: 0.8298\nStep 7600/46120, Loss: 0.9671, Accuracy: 0.8299\nStep 7700/46120, Loss: 0.9659, Accuracy: 0.8302\nStep 7800/46120, Loss: 0.9660, Accuracy: 0.8301\nStep 7900/46120, Loss: 0.9659, Accuracy: 0.8301\nStep 8000/46120, Loss: 0.9657, Accuracy: 0.8301\nStep 8100/46120, Loss: 0.9661, Accuracy: 0.8300\nStep 8200/46120, Loss: 0.9665, Accuracy: 0.8300\nStep 8300/46120, Loss: 0.9661, Accuracy: 0.8300\nStep 8400/46120, Loss: 0.9651, Accuracy: 0.8302\nStep 8500/46120, Loss: 0.9647, Accuracy: 0.8302\nStep 8600/46120, Loss: 0.9647, Accuracy: 0.8302\nStep 8700/46120, Loss: 0.9641, Accuracy: 0.8303\nStep 8800/46120, Loss: 0.9627, Accuracy: 0.8305\nStep 8900/46120, Loss: 0.9618, Accuracy: 0.8307\nStep 9000/46120, Loss: 0.9604, Accuracy: 0.8309\nStep 9100/46120, Loss: 0.9596, Accuracy: 0.8310\nStep 9200/46120, Loss: 0.9593, Accuracy: 0.8310\nStep 9300/46120, Loss: 0.9569, Accuracy: 0.8314\nStep 9400/46120, Loss: 0.9557, Accuracy: 0.8316\nStep 9500/46120, Loss: 0.9555, Accuracy: 0.8316\nStep 9600/46120, Loss: 0.9548, Accuracy: 0.8317\nStep 9700/46120, Loss: 0.9548, Accuracy: 0.8317\nStep 9800/46120, Loss: 0.9542, Accuracy: 0.8318\nStep 9900/46120, Loss: 0.9535, Accuracy: 0.8319\nStep 10000/46120, Loss: 0.9534, Accuracy: 0.8319\nStep 10100/46120, Loss: 0.9524, Accuracy: 0.8320\nStep 10200/46120, Loss: 0.9514, Accuracy: 0.8321\nStep 10300/46120, Loss: 0.9519, Accuracy: 0.8321\nStep 10400/46120, Loss: 0.9518, Accuracy: 0.8320\nStep 10500/46120, Loss: 0.9523, Accuracy: 0.8319\nStep 10600/46120, Loss: 0.9517, Accuracy: 0.8320\nStep 10700/46120, Loss: 0.9509, Accuracy: 0.8322\nStep 10800/46120, Loss: 0.9508, Accuracy: 0.8322\nStep 10900/46120, Loss: 0.9510, Accuracy: 0.8321\nStep 11000/46120, Loss: 0.9501, Accuracy: 0.8323\nStep 11100/46120, Loss: 0.9499, Accuracy: 0.8323\nStep 11200/46120, Loss: 0.9493, Accuracy: 0.8324\nStep 11300/46120, Loss: 0.9476, Accuracy: 0.8326\nStep 11400/46120, Loss: 0.9466, Accuracy: 0.8328\nStep 11500/46120, Loss: 0.9457, Accuracy: 0.8329\nStep 11600/46120, Loss: 0.9450, Accuracy: 0.8330\nStep 11700/46120, Loss: 0.9454, Accuracy: 0.8329\nStep 11800/46120, Loss: 0.9454, Accuracy: 0.8329\nStep 11900/46120, Loss: 0.9447, Accuracy: 0.8330\nStep 12000/46120, Loss: 0.9451, Accuracy: 0.8329\nStep 12100/46120, Loss: 0.9437, Accuracy: 0.8331\nStep 12200/46120, Loss: 0.9438, Accuracy: 0.8331\nStep 12300/46120, Loss: 0.9435, Accuracy: 0.8331\nStep 12400/46120, Loss: 0.9439, Accuracy: 0.8330\nStep 12500/46120, Loss: 0.9443, Accuracy: 0.8330\nStep 12600/46120, Loss: 0.9431, Accuracy: 0.8331\nStep 12700/46120, Loss: 0.9437, Accuracy: 0.8330\nStep 12800/46120, Loss: 0.9430, Accuracy: 0.8331\nStep 12900/46120, Loss: 0.9434, Accuracy: 0.8331\nStep 13000/46120, Loss: 0.9432, Accuracy: 0.8331\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[36], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m accuracy_metric\u001b[38;5;241m.\u001b[39mreset_states()\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_dataset):\n\u001b[0;32m----> 8\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mreduce_mean(loss)\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (step \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n","Cell \u001b[0;32mIn[32], line 7\u001b[0m, in \u001b[0;36mtrain_step\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m      5\u001b[0m     logits \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mlogits\n\u001b[1;32m      6\u001b[0m gradients \u001b[38;5;241m=\u001b[39m tape\u001b[38;5;241m.\u001b[39mgradient(loss, model\u001b[38;5;241m.\u001b[39mtrainable_variables)\n\u001b[0;32m----> 7\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_gradients\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgradients\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainable_variables\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m accuracy_metric\u001b[38;5;241m.\u001b[39mupdate_state(batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m], logits)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tf_keras/src/optimizers/optimizer.py:1223\u001b[0m, in \u001b[0;36mOptimizer.apply_gradients\u001b[0;34m(self, grads_and_vars, name, skip_gradients_aggregation, **kwargs)\u001b[0m\n\u001b[1;32m   1221\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m skip_gradients_aggregation \u001b[38;5;129;01mand\u001b[39;00m experimental_aggregate_gradients:\n\u001b[1;32m   1222\u001b[0m     grads_and_vars \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maggregate_gradients(grads_and_vars)\n\u001b[0;32m-> 1223\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_gradients\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrads_and_vars\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tf_keras/src/optimizers/optimizer.py:652\u001b[0m, in \u001b[0;36m_BaseOptimizer.apply_gradients\u001b[0;34m(self, grads_and_vars, name)\u001b[0m\n\u001b[1;32m    650\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply_weight_decay(trainable_variables)\n\u001b[1;32m    651\u001b[0m grads_and_vars \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(grads, trainable_variables))\n\u001b[0;32m--> 652\u001b[0m iteration \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_internal_apply_gradients\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrads_and_vars\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    654\u001b[0m \u001b[38;5;66;03m# Apply variable constraints after applying gradients.\u001b[39;00m\n\u001b[1;32m    655\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m variable \u001b[38;5;129;01min\u001b[39;00m trainable_variables:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tf_keras/src/optimizers/optimizer.py:1253\u001b[0m, in \u001b[0;36mOptimizer._internal_apply_gradients\u001b[0;34m(self, grads_and_vars)\u001b[0m\n\u001b[1;32m   1249\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mesh \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_with_dtensor:\n\u001b[1;32m   1250\u001b[0m     \u001b[38;5;66;03m# Skip any usage of strategy logic for DTensor\u001b[39;00m\n\u001b[1;32m   1251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m_internal_apply_gradients(grads_and_vars)\n\u001b[0;32m-> 1253\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__internal__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaybe_merge_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1254\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_distributed_apply_gradients_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1255\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_distribution_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1256\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrads_and_vars\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1257\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/distribute/merge_call_interim.py:51\u001b[0m, in \u001b[0;36mmaybe_merge_call\u001b[0;34m(fn, strategy, *args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Maybe invoke `fn` via `merge_call` which may or may not be fulfilled.\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \n\u001b[1;32m     33\u001b[0m \u001b[38;5;124;03mThe caller of this utility function requests to invoke `fn` via `merge_call`\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;124;03m  The return value of the `fn` call.\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m strategy_supports_no_merge_call():\n\u001b[0;32m---> 51\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstrategy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m distribute_lib\u001b[38;5;241m.\u001b[39mget_replica_context()\u001b[38;5;241m.\u001b[39mmerge_call(\n\u001b[1;32m     54\u001b[0m       fn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tf_keras/src/optimizers/optimizer.py:1345\u001b[0m, in \u001b[0;36mOptimizer._distributed_apply_gradients_fn\u001b[0;34m(self, distribution, grads_and_vars, **kwargs)\u001b[0m\n\u001b[1;32m   1342\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_step(grad, var)\n\u001b[1;32m   1344\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m grad, var \u001b[38;5;129;01min\u001b[39;00m grads_and_vars:\n\u001b[0;32m-> 1345\u001b[0m     \u001b[43mdistribution\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextended\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1346\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapply_grad_to_update_var\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m   1347\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1349\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_ema:\n\u001b[1;32m   1350\u001b[0m     _, var_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mgrads_and_vars)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py:3013\u001b[0m, in \u001b[0;36mStrategyExtendedV2.update\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   3010\u001b[0m   fn \u001b[38;5;241m=\u001b[39m autograph\u001b[38;5;241m.\u001b[39mtf_convert(\n\u001b[1;32m   3011\u001b[0m       fn, autograph_ctx\u001b[38;5;241m.\u001b[39mcontrol_status_ctx(), convert_by_default\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   3012\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_container_strategy()\u001b[38;5;241m.\u001b[39mscope():\n\u001b[0;32m-> 3013\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3014\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3015\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_replica_ctx_update(\n\u001b[1;32m   3016\u001b[0m       var, fn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs, group\u001b[38;5;241m=\u001b[39mgroup)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py:4083\u001b[0m, in \u001b[0;36m_DefaultDistributionExtended._update\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   4080\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update\u001b[39m(\u001b[38;5;28mself\u001b[39m, var, fn, args, kwargs, group):\n\u001b[1;32m   4081\u001b[0m   \u001b[38;5;66;03m# The implementations of _update() and _update_non_slot() are identical\u001b[39;00m\n\u001b[1;32m   4082\u001b[0m   \u001b[38;5;66;03m# except _update() passes `var` as the first argument to `fn()`.\u001b[39;00m\n\u001b[0;32m-> 4083\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_non_slot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py:4089\u001b[0m, in \u001b[0;36m_DefaultDistributionExtended._update_non_slot\u001b[0;34m(self, colocate_with, fn, args, kwargs, should_group)\u001b[0m\n\u001b[1;32m   4085\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update_non_slot\u001b[39m(\u001b[38;5;28mself\u001b[39m, colocate_with, fn, args, kwargs, should_group):\n\u001b[1;32m   4086\u001b[0m   \u001b[38;5;66;03m# TODO(josh11b): Figure out what we should be passing to UpdateContext()\u001b[39;00m\n\u001b[1;32m   4087\u001b[0m   \u001b[38;5;66;03m# once that value is used for something.\u001b[39;00m\n\u001b[1;32m   4088\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m UpdateContext(colocate_with):\n\u001b[0;32m-> 4089\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4090\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m should_group:\n\u001b[1;32m   4091\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m result\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:596\u001b[0m, in \u001b[0;36mcall_with_unspecified_conversion_status.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    595\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ag_ctx\u001b[38;5;241m.\u001b[39mControlStatusCtx(status\u001b[38;5;241m=\u001b[39mag_ctx\u001b[38;5;241m.\u001b[39mStatus\u001b[38;5;241m.\u001b[39mUNSPECIFIED):\n\u001b[0;32m--> 596\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tf_keras/src/optimizers/optimizer.py:1340\u001b[0m, in \u001b[0;36mOptimizer._distributed_apply_gradients_fn.<locals>.apply_grad_to_update_var\u001b[0;34m(var, grad)\u001b[0m\n\u001b[1;32m   1338\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_grad_to_update_var\u001b[39m(var, grad):\n\u001b[1;32m   1339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjit_compile:\n\u001b[0;32m-> 1340\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_step_xla\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_var_key\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvar\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1341\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1342\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_step(grad, var)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:877\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    874\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    875\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 877\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    881\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    882\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1319\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1321\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1322\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1323\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m     args,\n\u001b[1;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1327\u001b[0m     executing_eagerly)\n\u001b[1;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:249\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m InterpolateRuntimeError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    243\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mcontrol_dependencies(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_options\u001b[38;5;241m.\u001b[39mcontrol_captures):\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;66;03m# The caller must use record_operation to record this operation in the\u001b[39;00m\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;66;03m# eager case, so we enforce the same requirement for the non-eager\u001b[39;00m\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;66;03m# case by explicitly pausing recording. We don't have a gradient\u001b[39;00m\n\u001b[1;32m    247\u001b[0m     \u001b[38;5;66;03m# registered for PartitionedCall, so recording this operation confuses\u001b[39;00m\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;66;03m# forwardprop code (GradientTape manages to ignore it).\u001b[39;00m\n\u001b[0;32m--> 249\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m       \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m    251\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[1;32m    252\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m    253\u001b[0m             \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    254\u001b[0m             \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mflat_outputs),\n\u001b[1;32m    255\u001b[0m         )\n","File \u001b[0;32m/opt/conda/lib/python3.10/contextlib.py:142\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[0;34m(self, typ, value, traceback)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 142\u001b[0m         \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    144\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/record.py:64\u001b[0m, in \u001b[0;36mstop_recording\u001b[0;34m()\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     63\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_stopped:\n\u001b[0;32m---> 64\u001b[0m     \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_TapeSetRestartOnThread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}